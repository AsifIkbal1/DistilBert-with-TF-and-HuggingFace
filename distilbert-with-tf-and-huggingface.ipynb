{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Disaster Tweet Identification with HuggingFace DistilBert\n\nTransformers are very nice tools for NLP. I always found them a bit complex myself, but the HuggingFace libraries make it quite simple to use them. In this notebook, I use the DistilBert TF transformer model from HF for tweet classification. Works very well with a short notebook.\n\nA couple of articles I used as a basis: [article 1](https://medium.com/geekculture/hugging-face-distilbert-tensorflow-for-custom-text-classification-1ad4a49e26a7), [article 2](https://www.analyticsvidhya.com/blog/2022/04/building-state-of-the-art-text-classifier-using-huggingface-and-tensorflow/)","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\n\nfrom transformers import DistilBertTokenizer\nfrom transformers import TFDistilBertForSequenceClassification\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-10-22T16:09:43.641721Z","iopub.execute_input":"2022-10-22T16:09:43.642624Z","iopub.status.idle":"2022-10-22T16:09:58.377447Z","shell.execute_reply.started":"2022-10-22T16:09:43.642521Z","shell.execute_reply":"2022-10-22T16:09:58.376445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv(\"/kaggle/input/nlp-getting-started/train.csv\")\ndf_test = pd.read_csv(\"/kaggle/input/nlp-getting-started/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-10-22T16:10:05.961471Z","iopub.execute_input":"2022-10-22T16:10:05.962896Z","iopub.status.idle":"2022-10-22T16:10:06.021033Z","shell.execute_reply.started":"2022-10-22T16:10:05.962847Z","shell.execute_reply":"2022-10-22T16:10:06.020113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I combined the location + keywords + tweet text into a single field that I use as input for the transformer (text_combo field). I got just as good results with just the tweet text, so this is quite pointless really. But a reminder that it is simple to experiment with these things.","metadata":{}},{"cell_type":"code","source":"df_train['text_combo'] = df_train['location'].astype(str) + \" : \" + df_train['keyword'].astype(str) + \" : \" + df_train['text'].astype(str)\ndf_test['text_combo'] = df_test['location'].astype(str) + \" : \" + df_test['keyword'].astype(str) + \" : \" + df_test['text'].astype(str)\n","metadata":{"execution":{"iopub.status.busy":"2022-10-22T16:10:06.911735Z","iopub.execute_input":"2022-10-22T16:10:06.912087Z","iopub.status.idle":"2022-10-22T16:10:06.937603Z","shell.execute_reply.started":"2022-10-22T16:10:06.912051Z","shell.execute_reply":"2022-10-22T16:10:06.936702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train_subset = df_train[[\"text_combo\", \"target\"]].copy()\ndf_train_subset.rename(columns = {'text_combo':'text'}, inplace = True)\nX_train, X_test = train_test_split(df_train_subset, test_size=0.05, random_state=0, stratify=df_train[\"target\"])","metadata":{"execution":{"iopub.status.busy":"2022-10-22T16:10:06.944035Z","iopub.execute_input":"2022-10-22T16:10:06.944307Z","iopub.status.idle":"2022-10-22T16:10:06.961263Z","shell.execute_reply.started":"2022-10-22T16:10:06.944283Z","shell.execute_reply":"2022-10-22T16:10:06.960421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MODEL_NAME = 'distilbert-base-uncased-finetuned-sst-2-english'\nBATCH_SIZE = 16\n#generally I got the best results already after epoch 1 \n#but it is good to try and see with a few more\nN_EPOCHS = 3","metadata":{"execution":{"iopub.status.busy":"2022-10-22T16:10:06.965539Z","iopub.execute_input":"2022-10-22T16:10:06.965891Z","iopub.status.idle":"2022-10-22T16:10:06.970968Z","shell.execute_reply.started":"2022-10-22T16:10:06.965862Z","shell.execute_reply":"2022-10-22T16:10:06.969889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Tokenization","metadata":{}},{"cell_type":"code","source":"#HuggingFace models come with their own tokenizes, suitable for what input it expects\ntokenizer = DistilBertTokenizer.from_pretrained(MODEL_NAME)","metadata":{"execution":{"iopub.status.busy":"2022-10-22T16:10:07.026917Z","iopub.execute_input":"2022-10-22T16:10:07.02718Z","iopub.status.idle":"2022-10-22T16:10:07.994554Z","shell.execute_reply.started":"2022-10-22T16:10:07.027157Z","shell.execute_reply":"2022-10-22T16:10:07.993636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#tokenize the text\ntrain_encodings = tokenizer(list(X_train[\"text\"]),\n                            truncation=True, \n                            padding=True)\n\ntest_encodings = tokenizer(list(X_test[\"text\"]),\n                           truncation=True, \n                           padding=True)\n","metadata":{"execution":{"iopub.status.busy":"2022-10-22T16:10:07.996431Z","iopub.execute_input":"2022-10-22T16:10:07.99687Z","iopub.status.idle":"2022-10-22T16:10:14.671202Z","shell.execute_reply.started":"2022-10-22T16:10:07.996833Z","shell.execute_reply":"2022-10-22T16:10:14.670236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Tokenization Example\n\nMaybe we can learn something about looking at how the tokenizer handles some input?","metadata":{}},{"cell_type":"code","source":"X_train[\"text\"].iloc[188]","metadata":{"execution":{"iopub.status.busy":"2022-10-22T16:10:14.673428Z","iopub.execute_input":"2022-10-22T16:10:14.674114Z","iopub.status.idle":"2022-10-22T16:10:14.683738Z","shell.execute_reply.started":"2022-10-22T16:10:14.674072Z","shell.execute_reply":"2022-10-22T16:10:14.682711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_ids = train_encodings[\"input_ids\"][188]\ntokens = tokenizer.convert_ids_to_tokens(input_ids)\n#print(f\"Tokenized output: {output}\")\nprint(f\"Tokenized tokens: {tokens}\")\nprint(f\"Tokenized text: {tokenizer.convert_tokens_to_string(tokens)}\")","metadata":{"execution":{"iopub.status.busy":"2022-10-22T16:10:14.686792Z","iopub.execute_input":"2022-10-22T16:10:14.687148Z","iopub.status.idle":"2022-10-22T16:10:14.694682Z","shell.execute_reply.started":"2022-10-22T16:10:14.687114Z","shell.execute_reply":"2022-10-22T16:10:14.693552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It seems the max length could be shorter, since tweets rarely will be that many words / tokens. Also it seems to lowercase all text, and separate special chars such as #.","metadata":{}},{"cell_type":"code","source":"\ntrain_dataset = tf.data.Dataset.from_tensor_slices((dict(train_encodings),\n                                    list(X_train[\"target\"].values)))\n\ntest_dataset = tf.data.Dataset.from_tensor_slices((dict(test_encodings),\n                                    list(X_test[\"target\"].values)))","metadata":{"execution":{"iopub.status.busy":"2022-10-22T16:10:14.696508Z","iopub.execute_input":"2022-10-22T16:10:14.696905Z","iopub.status.idle":"2022-10-22T16:10:18.410079Z","shell.execute_reply.started":"2022-10-22T16:10:14.696872Z","shell.execute_reply":"2022-10-22T16:10:18.409114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Training","metadata":{"execution":{"iopub.status.busy":"2022-10-22T09:00:58.495184Z","iopub.execute_input":"2022-10-22T09:00:58.496352Z","iopub.status.idle":"2022-10-22T09:01:00.809096Z","shell.execute_reply.started":"2022-10-22T09:00:58.496278Z","shell.execute_reply":"2022-10-22T09:01:00.808126Z"}}},{"cell_type":"code","source":"model = TFDistilBertForSequenceClassification.from_pretrained(MODEL_NAME)#chose the optimizer\n#optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)#define the loss function \noptimizer = tf.keras.optimizers.Adam(learning_rate=18e-6)#define the loss function \nlosss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)#build the model\n\nmodel.compile(optimizer=optimizer,\n              loss=losss,\n              metrics=['accuracy'])\n\ncheckpoint_filepath = 'mycheckpoint'\nmodel_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n    filepath=checkpoint_filepath,\n    save_weights_only=True,\n    monitor='val_loss',\n    mode='min',\n    save_best_only=True)\n\nmodel.fit(train_dataset.shuffle(len(X_train)).batch(BATCH_SIZE),\n          epochs=N_EPOCHS,\n          batch_size=BATCH_SIZE,\n          callbacks=[model_checkpoint_callback],\n          validation_data=test_dataset.shuffle(len(X_train)).batch(1))","metadata":{"execution":{"iopub.status.busy":"2022-10-22T16:10:18.411364Z","iopub.execute_input":"2022-10-22T16:10:18.411742Z","iopub.status.idle":"2022-10-22T16:13:51.486744Z","shell.execute_reply.started":"2022-10-22T16:10:18.411707Z","shell.execute_reply":"2022-10-22T16:13:51.486018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#now to load the saved best model weights\nmodel.load_weights(checkpoint_filepath)","metadata":{"execution":{"iopub.status.busy":"2022-10-22T16:13:51.488425Z","iopub.execute_input":"2022-10-22T16:13:51.489165Z","iopub.status.idle":"2022-10-22T16:13:52.261393Z","shell.execute_reply.started":"2022-10-22T16:13:51.489124Z","shell.execute_reply":"2022-10-22T16:13:52.260411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Test Set Prediction","metadata":{}},{"cell_type":"code","source":"def predict_proba(text_list, model, tokenizer):\n    encodings = tokenizer(text_list, \n                          #max_length=MAX_LEN, \n                          truncation=True, \n                          padding=True)\n\n    #somehow these API's never read very intuitively :/ \n    dataset = tf.data.Dataset.from_tensor_slices((dict(encodings)))\n    #the batch(1) seems to be required for the call..\n    preds = model.predict(dataset.batch(1)).logits  \n    \n    #transform to array with probabilities\n    res = tf.nn.softmax(preds, axis=1).numpy()      \n    \n    return res","metadata":{"execution":{"iopub.status.busy":"2022-10-22T16:13:52.262914Z","iopub.execute_input":"2022-10-22T16:13:52.263805Z","iopub.status.idle":"2022-10-22T16:13:52.270919Z","shell.execute_reply.started":"2022-10-22T16:13:52.263766Z","shell.execute_reply":"2022-10-22T16:13:52.269924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#test_texts = list(df_test[\"text\"])\ntest_texts = list(df_test[\"text_combo\"])","metadata":{"execution":{"iopub.status.busy":"2022-10-22T16:13:52.272252Z","iopub.execute_input":"2022-10-22T16:13:52.272747Z","iopub.status.idle":"2022-10-22T16:13:52.284637Z","shell.execute_reply.started":"2022-10-22T16:13:52.27271Z","shell.execute_reply":"2022-10-22T16:13:52.283259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = predict_proba(test_texts, model, tokenizer)","metadata":{"execution":{"iopub.status.busy":"2022-10-22T16:13:52.288502Z","iopub.execute_input":"2022-10-22T16:13:52.288784Z","iopub.status.idle":"2022-10-22T16:14:38.051129Z","shell.execute_reply.started":"2022-10-22T16:13:52.288745Z","shell.execute_reply":"2022-10-22T16:14:38.050013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predictions Distribution\n\nFirst the predictions for 0 (not disaster), followed by 1 (disaster)","metadata":{}},{"cell_type":"code","source":"n, bins, patches = plt.hist(preds[:,0])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-10-22T16:14:38.054266Z","iopub.execute_input":"2022-10-22T16:14:38.055575Z","iopub.status.idle":"2022-10-22T16:14:38.279789Z","shell.execute_reply.started":"2022-10-22T16:14:38.055541Z","shell.execute_reply":"2022-10-22T16:14:38.278896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n, bins, patches = plt.hist(preds[:,1])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-10-22T16:14:38.281271Z","iopub.execute_input":"2022-10-22T16:14:38.281642Z","iopub.status.idle":"2022-10-22T16:14:38.47335Z","shell.execute_reply.started":"2022-10-22T16:14:38.281607Z","shell.execute_reply":"2022-10-22T16:14:38.472291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"df_submission = pd.DataFrame()\ndf_submission[\"id\"] = df_test[\"id\"]\ndf_submission[\"target\"] = preds[:, 1] >= 0.5\ndf_submission[\"target\"] = df_submission[\"target\"].astype(int)\ndf_submission","metadata":{"execution":{"iopub.status.busy":"2022-10-22T16:14:38.474748Z","iopub.execute_input":"2022-10-22T16:14:38.475081Z","iopub.status.idle":"2022-10-22T16:14:38.494361Z","shell.execute_reply.started":"2022-10-22T16:14:38.475047Z","shell.execute_reply":"2022-10-22T16:14:38.493551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_submission.to_csv(\"kaggle_submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-10-22T16:14:38.495699Z","iopub.execute_input":"2022-10-22T16:14:38.49658Z","iopub.status.idle":"2022-10-22T16:14:38.506232Z","shell.execute_reply.started":"2022-10-22T16:14:38.496533Z","shell.execute_reply":"2022-10-22T16:14:38.505577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!head kaggle_submission.csv","metadata":{"execution":{"iopub.status.busy":"2022-10-22T16:14:38.50758Z","iopub.execute_input":"2022-10-22T16:14:38.508711Z","iopub.status.idle":"2022-10-22T16:14:39.537071Z","shell.execute_reply.started":"2022-10-22T16:14:38.508676Z","shell.execute_reply":"2022-10-22T16:14:39.535901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}